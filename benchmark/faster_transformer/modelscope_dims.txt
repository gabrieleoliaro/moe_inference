Modelscope nlp_gpt3_text-generation_0.35B_MoE-64 weight dimensions
positional embedding weight: 	[2048, 1024]
token embedding weight : 		[51200, 1024]
layernorm gamma/beta: 			[1024]
attention qkv weights: 			[1024, 3072]
attention qkv bias: 			[3072]
attention out proj weights: 	[1024, 1024]
attention out proj bias: 		[1024]
ffn/expert h to 4h weights: 	[1024, 4096]
ffn/expert bias 1 weights: 		[4096]
ffn/expert 4h to h weights:		[4096, 1024]
ffn/expert bias 2 weights: 		[1024]